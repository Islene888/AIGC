# AIGC (AI-Generated Content Platform)

AIGC is a modular analytics framework for evaluating the quality, engagement, and growth performance of AI-generated conversational bots at scale. This repository powers the internal analytics behind FlowGPTâ€™s bot ecosystem, supporting metric computation, A/B testing, and dashboard reporting across thousands of workflows.

## ğŸš€ Core Capabilities

- **Engagement Analytics**: Compute CTR, chat start rate, depth, and user-level stickiness for 5K+ bots.
- **Retention & LTV Analysis**: Track Day 1/3/7 retention and subscription-based revenue (ARPU, LTV, renewal rate).
- **A/B Experiment Evaluation**: Bayesian uplift modeling to compare variants using GrowthBook labels.
- **Bot Performance Tagging**: Automatically evaluate and rank bots by engagement tiers.
- **Pipeline Automation**: Batch execution with `run_all_metrics.py` and modular logic per metric.

## ğŸ› ï¸ Tech Stack

- Python, PySpark, SQL
- StarRocks (OLAP DB), Kafka, Flink, S3
- DolphinScheduler (workflow orchestration)
- Metabase, Superset (visualization)
- GrowthBook (A/B test labels)

## ğŸ“ Repository Structure

```
AIGC/
â”œâ”€â”€ bayes/                # Bayesian uplift & win rate calculation
â”œâ”€â”€ bots/                 # Overall bot-level performance computation
â”œâ”€â”€ chat/                 # Chat depth per bot/user computation
â”œâ”€â”€ click/                # Exposure â†’ Click conversion metrics
â”œâ”€â”€ experiments/          # Experiment label parsing & variation comparison
â”œâ”€â”€ retention/            # Daily and cohort-based retention logic
â”œâ”€â”€ subscribe/            # Subscription events, ARPU, renewal rate
â”œâ”€â”€ test/                 # Unit tests & validation logic
â”œâ”€â”€ utils/                # Shared constants, grouping, and data tools
â”œâ”€â”€ zip/                  # Output packaging and compression
â””â”€â”€ run_all_metrics.py    # Main controller script to execute all metrics
```

## â–¶ï¸ Quick Start

```bash
git clone https://github.com/Islene888/AIGC.git
cd AIGC/AIGC

# Optional environment setup
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Execute all metrics
python run_all_metrics.py
```

## ğŸ“Š Output Metrics (Selected)

- `bot_ctr`, `chat_start_rate`, `chat_depth_user`
- `user_retention_d1/d3/d7`, `ltv`, `payment_rate`
- `uplift`, `win_rate`, `variation_summary`
- `subscribe_dau_rate`, `arpu_by_tag`, `bot_ranking_by_tier`

## ğŸ§ª Example Use Cases

- Identify underperforming bots with low engagement or negative uplift
- Compare model variants in new bot strategies using Bayesian metrics
- Monitor subscription LTV trends across tag or workflow segments

## ğŸ“„ License

MIT License Â© 2025 Mengyuan (Ella) Zhao
